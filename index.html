<!DOCTYPE HTML>
<html>
	<head>
		<title>Alfred Suli - Portfolio</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
		<div id="wrapper">

			<!-- Main -->
			<div id="main">
				<div class="inner">

					<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo"><strong>Alfred Suli</strong> Portfolio</a>
					</header>

					<!-- Banner -->
					<section id="banner">
					  <div class="content">
						<header>
						  <h1>Hello, I'm SU LI (Alfred)</h1>
						  <p>
							I am passionate about <strong>Computer Graphics</strong>, 
							<strong>GPU Programming</strong>, 
							<strong>VR/AR</strong>, and 
							<strong>Computer Vision</strong>, and
							<strong>User-Centered Design</strong>.
							<br>
							Below are some projects I have worked on.
						  </p>
						</header>
						  <!-- Education Background -->
<section id="education">
  <header class="major">
    <h2>Education Background</h2>
  </header>
  <div class="timeline">

    <!-- Master -->
    <div class="edu-entry">
      <h3>Lund University <span style="font-weight:normal;">— Lund, Sweden</span></h3>
      <p><strong>M.Sc. in Virtual Reality and Augmented Reality</strong> (2023 – 2025)</p>
      <ul>
        <li><strong>Thesis:</strong> Enhancing Game Accessibility — High Contrast Mode for Low-Vision Players (with IO Interactive)</li>
        <li><strong>Relevant Coursework:</strong> Computer Graphics, Augmented & Virtual Reality, High Performance Computer Graphics, Computer Vision</li>
      </ul>
    </div>

    <!-- Bachelor -->
    <div class="edu-entry">
      <h3>North China Electric Power University <span style="font-weight:normal;">— Beijing, China</span></h3>
      <p><strong>Bachelor in Computer Science and Technology</strong> (2019 – 2023)</p>
      <ul>
        <li><strong>Relevant Coursework:</strong> Operating Systems, Linux, Data Structures and Algorithms, Software Engineering, Computer Graphics, Computer Architecture</li>
        <li><strong>GPA:</strong> 86.7 / 100</li>
      </ul>
    </div>

  </div>
</section>

					  </div>
					  <span class="image object">
						<img id="coverImage" src="images/alfred1.jpg" alt="Cover image" />
					  </span>
					</section>

					<!-- Script for image slideshow -->
					<script>
					  const photos = [
						"images/alfred1.jpg",
						"images/alfred2.jpg",
						"images/alfred3.jpg"
					  ];
					  let i = 0;
					  setInterval(() => {
						i = (i + 1) % photos.length;
						document.getElementById("coverImage").src = photos[i];
					  }, 3000);
					</script>
                     

					<!-- Skills -->
<section id="skills">
  <header class="major">
    <h2>Skills</h2>
  </header>
  <ul>
    <li><strong>Programming:</strong> Java, C, C++, C# (basic), Python (basic), Swift (basic)</li>
    <li><strong>Graphics APIs:</strong> OpenGL, HlSL, BGFX, GLSL</li>
    <li><strong>Engines & Frameworks:</strong> Unity, ARKit/ARFoundation</li>
    <li><strong>Tools:</strong> Git, Linux, LaTeX</li>
	<li><strong>Others:</strong> Matlab, Blender</li>
  </ul>
</section>

					<!-- Computer Graphics Projects -->
					<section>
						<header class="major">
							<h2>Computer Graphics Projects</h2>
						</header>
						<div class="posts">


							<!-- Project 1 -->
						<article id="project1" class="project-detail">
  <h2>Cloth Simulation based on OpenGL and computer shader</h2>
  <p>
      The cloth is represented by particles and springs using a mass–spring model (structural, shearing, bending). 
	  All forces and integration are computed in parallel on the GPU to achieve real-time cloth simulation.
  </p>

  <!-- 实现要点 -->
  <h3>Key Implementation Points</h3>
  <ul>
    <li>Particle System: Verlet/semi-implicit integration with position, velocity, force, and fixed-point flags.</li>
    <li>Spring Constraints: Structural, shearing, and bending springs, evaluated in parallel on the GPU.</li>
    <li>GPU Architecture: Particle and spring data stored in SSBOs, with Compute Shaders handling force accumulation and updates.</li>
    <li>Color Constraint: Partitioning constraints to prevent data races during parallel updates.</li>
	<li>Self-Collision: Neighbor-based detection prevents cloth self-intersections, maintaining thickness and producing realistic folds.</li>
	<li>Collision Handling: Enable Collision with other objects and plane.</li>	
  </ul>

  <!-- GIF 展示 -->
  <div class="media-grid">
    <figure>
      <img src="images/cloth_overview.gif" alt="Overview" />
      <figcaption>Overview of the cloth behavior under gravity + wind.</figcaption>
    </figure>
    <figure>
      <img src="images/collision_with_sphere.png" alt="Collision" style="width:30%;" />
      <figcaption>Collision with sphere.</figcaption>
    </figure>
    <figure>
      <img src="images/collision_with_cylinder.png" alt="Collision" style="width:30%;" />
      <figcaption>Collision with cylinder.</figcaption>
    </figure>
  </div>

  <!-- 改进目标 -->
  <h3>Future Improvements</h3>
  <p>
  I aim to explore an alternative architecture beyond the traditional particle–spring model, by adopting more advanced approaches such as finite element methods (FEM) on triangular meshes. 
  A preliminary framework has already been implemented, though stability remains a challenge. 
  Future work will focus on improving robustness and experimenting with more advanced cloth simulation techniques.
  </p>
</article>

							<!-- Project 2 -->
<article class="project-detail">
  <h2>Project 2: Terrain Rendering with Procedural Generation</h2>

  <h4>Overview</h4>
  <p>
    This project focuses on procedural terrain rendering based on heightmap generation. 
    The system supports multiple algorithms for creating diverse terrains and is built on 
    a custom framework developed with OpenGL. The framework integrates camera, GUI, 
    heightmap generation, mesh construction, and rendering into a cohesive system.
  </p>

  <h4>Key Implementations</h4>

  <h5>Heightmap Generation Methods</h5>

  <figure>
    <img src="images/terrain_perlin.gif" alt="Perlin Noise Terrain" />
    <figcaption><strong>Perlin Noise</strong> — smooth and natural variation.</figcaption>
  </figure>

  <figure>
    <img src="images/terrain_fault.gif" alt="Fault Formation Terrain" />
    <figcaption><strong>Fault Formation</strong> — sharp ridges and cliffs.</figcaption>
  </figure>

  <figure>
    <img src="images/terrain_midpoint.gif" alt="Midpoint Displacement Terrain" />
    <figcaption><strong>Midpoint Displacement</strong> — fractal-style mountainous terrain.</figcaption>
  </figure>

  <h5>Configurable Parameters</h5>
  <p>
    Resolution, iteration count, and elevation range can be adjusted to produce varied terrain.
  </p>

  <h5>Runtime Control</h5>
  <p>
    Heightmaps can be regenerated and switched between algorithms during program execution.
  </p>
</article>


							<!-- Project 3 -->
<article class="project-detail">
  <h2>Project 3: Volumetric Cloud Rendering with Raymarching</h2>

  <h4>Overview</h4>
  <p>
    This project focuses on volumetric cloud rendering through raymarching, 
    implemented with the bgfx framework and OpenGL. To enhance realism, 
    I implemented custom noise functions in shaders, inspired by 
    Perlin, Simplex, and Worley noise. While Worley was tested with limited effect, 
    the Perlin-like and Simplex variants produced convincing cloud structures.
  </p>

  <h4>Key Implementations</h4>
  <ul>
    <li><strong>Raymarching</strong> — fragment shader implementation for sampling volumetric density.</li>
    <li><strong>Custom Noise Functions</strong> — shader-based noise functions inspired by:
      <ul>
        <li>Perlin-like noise — smooth, layered cloud structures.</li>
        <li>Simplex noise — sharper detail and variation.</li>
        <li>Worley noise — tested but less effective for this case.</li>
      </ul>
    </li>
    <li><strong>Framework</strong> — built with bgfx on top of OpenGL for rendering and shader management.</li>
  </ul>

  <h4>Results</h4>
  <div class="media-grid">
    <figure>
      <img src="images/cloud_perlin.gif" alt="Perlin-like Cloud Rendering" style="width:50%;" />
      <figcaption>Perlin-like noise producing smooth volumetric clouds.</figcaption>
    </figure>
    <figure>
      <img src="images/cloud_simplex.gif" alt="Simplex Cloud Rendering" style="width:50%;" />
      <figcaption>Simplex noise adding sharper details and variation.</figcaption>
    </figure>
  </div>
</article>

							<!-- Project 4 -->
<article class="project-detail">
  <video autoplay loop muted playsinline style="max-width: 100%; border-radius: 8px;">
    <source src="images/project4.mp4" type="video/mp4">
    Your browser does not support the video tag.
  </video>

  <h3>Project 4: Particle-based Fluid Simulation with Compute Shader</h3>

  <h4>Overview</h4>
  <p>
    This project implements a particle-based fluid simulation using OpenGL and Compute Shaders. 
    The fluid is represented by particles carrying mass, velocity, and pressure, with all physics 
    computations executed in parallel on the GPU. Rendering is achieved through instancing to 
    efficiently draw thousands of particles in real time. My main contribution focused on the 
    implementation and debugging of the Compute Shaders. 
    The video above demonstrates the final 2D fluid simulation.
  </p>

  <h4>Key Implementations</h4>
  <ul>
    <li><strong>Particle Emitter:</strong> initializes particle positions and velocities.</li>
    <li><strong>Compute Shader Physics:</strong> density and near-density calculation within a smoothing radius; 
        pressure and near-pressure force computation; gravity and viscosity terms for stability.</li>
    <li><strong>Instanced Rendering:</strong> efficient batch drawing of large particle sets.</li>
    <li><strong>Visualization:</strong> particle color encodes velocity magnitude (faster particles appear redder).</li>
  </ul>
</article>

							<!-- Project 5 -->
<article class="project-detail">
  <h2>Project 5: Optimizing Ray Tracing in The Rest of Your Life</h2>

  <h4>Overview</h4>
  <p>
    This project focuses on optimizing the renderer from the well-known 
    <em>Ray Tracing in One Weekend</em> series (<em>The Rest of Your Life</em>). 
    Although the implementation remains CPU-based, several improvements were introduced 
    to significantly accelerate rendering and improve image quality. 
    The optimized version reduces render time from about <strong>75 seconds to 19 seconds</strong>, 
    while producing cleaner images with reduced noise.
  </p>

  <h4>Key Optimizations</h4>
  <ul>
    <li><strong>Multithreading with Adaptive Sampling</strong> – Replaced the original single-threaded renderer with a multi-threaded version using <code>std::thread</code>, adaptive sampling based on variance, and sample clamping.</li>
    <li><strong>Iterative Path Tracing with Next-Event Estimation (NEE)</strong> – Converted recursive path tracing into an iterative loop, added explicit light sampling, multiple importance sampling (MIS), and Russian Roulette termination.</li>
    <li><strong>High-Quality Random Number Generation (PCG)</strong> – Replaced the default random generator with PCG, improving sample distribution and reducing noise.</li>
    <li><strong>BVH Integration</strong> – Used the existing BVH structure to reduce ray–scene intersection overhead.</li>
  </ul>

  <h4>Results</h4>
  <div class="media-grid">
    <figure>
      <img src="images/imageOriginal.png" alt="Original Rendering" />
      <figcaption>Original rendering (~75s, noisy).</figcaption>
    </figure>
    <figure>
      <img src="images/newImage.png" alt="Optimized Rendering" />
      <figcaption>Optimized rendering (~19s, cleaner output).</figcaption>
    </figure>
  </div>
</article>
							<!-- Project 6 -->
<article class="project expandable">
  <h3>Master Thesis – Enhancing Game Accessibility: Implementing High
 Contrast Mode in Games for Players with Low Vision</h3>
  <p>
    In collaboration with IO Interactive, I designed and implemented customizable high-contrast modes 
    in a modern game engine to improve accessibility for low-vision players.  
  </p>
  <button class="toggle-btn">[Click to read more]</button>

  <!-- 折叠详情 -->
  <div class="details">
    <h2>Master Thesis – High-Contrast Rendering for Accessibility</h2>

    <p>
      This thesis project, conducted in collaboration with IO Interactive, explored how to implement 
      high-contrast modes in modern game engines to enhance accessibility for low-vision players. 
      By introducing shader-based rendering modifications and post-processing techniques, 
      a customizable accessibility mode was developed to improve object recognition and visual clarity 
      while maintaining game aesthetics.
    </p>

    <h3>My Contributions</h3>

    <!-- 1 -->
    <h4>1. Accessibility Mode design</h4>
    <p>I completed the overall design of the accessibility mode.</p>
    <img src="images/structure_chart.png" alt="Accessibility mode structure" style="max-width:100%; border-radius:8px; margin:1rem 0;">

    <!-- 2 -->
    <h4>2. Smart De-saturation for Accessibility</h4>
    <p>Implemented a de-saturation mode that adapts color reduction while keeping key elements highlighted.</p>
    <div class="media-grid">
      <figure><img src="images/original.png" alt="Original"><figcaption>Original</figcaption></figure>
      <figure><img src="images/greyscale.png" alt="Greyscale"><figcaption>Uniform grayscale</figcaption></figure>
      <figure><img src="images/smart_desaturation.png" alt="Smart"><figcaption>Smart de-saturation</figcaption></figure>
    </div>

    <!-- 3 -->
    <h4>3. Lighting Module design</h4>
    <p>Designed a three-stage lighting module to enhance scene readability.</p>
    <img src="images/lighting_module.png" alt="Lighting module structure" style="max-width:100%; border-radius:8px; margin:1rem 0;">
    <ul>
      <li><strong>Retinex-inspired adjustment</strong> – improve local contrast</li>
      <li><strong>Contrast enhancement</strong> – balance dark/bright regions</li>
      <li><strong>Filmic tone mapping</strong> – compress highlights and recover shadow detail</li>
    </ul>
    <div class="media-grid two">
      <figure><img src="images/filmic_before.png" alt="Before"><figcaption>Before tone mapping</figcaption></figure>
      <figure><img src="images/filmic_after.png" alt="After"><figcaption>After tone mapping</figcaption></figure>
    </div>

    <!-- 4 -->
    <h4>4. Brightness-based blending</h4>
    <p>Added a blending technique that dynamically adjusts based on pixel brightness.</p>
    <div class="media-grid">
      <figure><img src="images/original_blend.png" alt="Original"><figcaption>Original</figcaption></figure>
      <figure><img src="images/witout_details.png" alt="Opaque"><figcaption>Opaque rendering</figcaption></figure>
      <figure><img src="images/keep_details.png" alt="Blended"><figcaption>Blended result</figcaption></figure>
    </div>

    <p style="margin-top:2rem; font-style:italic;">
      If you are interested in more technical details, please refer to the full thesis at: 
      <a href="https://lup.lub.lu.se/luur/download?func=downloadFile&recordOId=9198324&fileOId=9198326" target="_blank">[thesis link]</a>.
    </p>
  </div>
</article>
						</div>
					</section>

					<!-- VR/AR Projects -->
					<section>
						<header class="major">
							<h2>VR/AR Projects</h2>
						</header>
						<div class="posts">

							<!-- VR Project Example -->
							<article class="project-detail">
							  <h2>Cyber Guard — VR Crime Scene Investigation</h2>
							  <p>
								Cyber Guard is a VR project developed in Unity as a group work. We created a custom 3D scene where
    players can observe crime scenarios through in-scene cameras, replay the timeline of events using a
    slide system, and scan the environment to discover interactive objects. The goal is to track the
    suspect’s movements and ultimately solve the case. The gif shows how the crime scenarios in the project like.
							  </p>
							  <div class="media-grid">
								<figure>
								 <video autoplay loop muted playsinline style="max-width:100%; border-radius:8px;">
    <source src="images/cyberguard_scene.mp4" type="video/mp4">
    Your browser does not support the video tag.
  </video>
  <figcaption>Overview of the Cyber Guard</figcaption>
								</figure>
							  </div>
							</article>

							<!-- AR Project Example -->
							<article class="project-detail">
							  <h2>AR LEGO Assembly Assistant</h2>
							  <p>
    This AR project was designed to assist users in assembling LEGO bricks into specific patterns. 
    In our prototype, we chose the <strong>Super Mario</strong> pattern as a demonstration case. 
    The system highlights the exact positions on the baseplate where bricks should be placed and 
    overlays the correct colors to guide the assembly. 
    The project was developed for iOS using <strong>Swift</strong> and ARKit.
							  </p>
							  <div class="media-grid">
								<figure>
								<video autoplay loop muted playsinline style="max-width:100%; border-radius:8px;">
    <source src="images/lego.mp4" type="video/mp4">
    Your browser does not support the video tag.
  </video>
  <figcaption>AR LEGO assembly guidance</figcaption>
								</figure>
							  </div>
							</article>

						</div>
					</section>

					<!-- Contact -->
					<section>
						<header class="major">
							<h2>Get in touch</h2>
						</header>
						<ul class="contact">
							<li class="icon solid fa-envelope"><a href="mailto:your.email@example.com">suli.alfred.0115@gmail.com</a></li>
							<li class="icon solid fa-envelope"><a href="mailto:your.email@example.com">su8507li-s@student.lu.se</a></li>
							<li class="icon brands fa-github"><a href="https://github.com/Alfred-suli">https://github.com/Alfred-suli</a></li>
						</ul>
					</section>

				</div>
			</div>
		</div>

		<!-- Scripts -->
		<script src="assets/js/jquery.min.js"></script>
		<script src="assets/js/browser.min.js"></script>
		<script src="assets/js/breakpoints.min.js"></script>
		<script src="assets/js/util.js"></script>
		<script src="assets/js/main.js"></script>
		<script>
		document.querySelectorAll('.project.expandable .toggle-btn').forEach(btn => {
		  btn.addEventListener('click', e => {
			const article = e.target.closest('.project.expandable');
			article.classList.toggle('open');
			btn.textContent = article.classList.contains('open') 
			  ? "[Click to collapse]" 
			  : "[Click to read more]";
		  });
		});
		</script>

	</body>
</html>


































